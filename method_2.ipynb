{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest, SVM, and KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"D:\\IIT\\Subjects\\(4605)IRP\\Devlo\\Augmented_DataSet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LBP_RADIUS = 1\n",
    "LBP_POINTS = 8 * LBP_RADIUS\n",
    "GLCM_DISTANCES = [1, 2]\n",
    "GLCM_ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image):\n",
    "    features = {}\n",
    "    \n",
    "    image = cv2.resize(image, (128, 128))\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Color Features\n",
    "    features['mean_r'] = np.mean(image[:, :, 0])\n",
    "    features['mean_g'] = np.mean(image[:, :, 1])\n",
    "    features['mean_b'] = np.mean(image[:, :, 2])\n",
    "    features['std_r'] = np.std(image[:, :, 0])\n",
    "    features['std_g'] = np.std(image[:, :, 1])\n",
    "    features['std_b'] = np.std(image[:, :, 2])\n",
    "    \n",
    "    # Grayscale histogram\n",
    "    hist = cv2.calcHist([gray], [0], None, [256], [0, 256]).flatten()\n",
    "    features['hist_mean'] = np.mean(hist)\n",
    "    features['hist_std'] = np.std(hist)\n",
    "    \n",
    "    # Texture Features (LBP)\n",
    "    lbp = local_binary_pattern(gray, LBP_POINTS, LBP_RADIUS, method=\"uniform\")\n",
    "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, LBP_POINTS + 3), range=(0, LBP_POINTS + 2))\n",
    "    lbp_hist = lbp_hist.astype(\"float\")\n",
    "    lbp_hist /= (lbp_hist.sum() + 1e-6)\n",
    "    features['lbp_mean'] = np.mean(lbp_hist)\n",
    "    features['lbp_std'] = np.std(lbp_hist)\n",
    "    \n",
    "    # Texture Features (GLCM)\n",
    "    glcm = graycomatrix(gray, distances=GLCM_DISTANCES, angles=GLCM_ANGLES, symmetric=True, normed=True)\n",
    "    features['glcm_contrast'] = np.mean(graycoprops(glcm, 'contrast'))\n",
    "    features['glcm_energy'] = np.mean(graycoprops(glcm, 'energy'))\n",
    "    features['glcm_homogeneity'] = np.mean(graycoprops(glcm, 'homogeneity'))\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataset(image_dir):\n",
    "    feature_list = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(image_dir):\n",
    "        class_dir = os.path.join(image_dir, label)\n",
    "        if not os.path.isdir(class_dir):\n",
    "            continue\n",
    "        for img_name in os.listdir(class_dir):\n",
    "            img_path = os.path.join(class_dir, img_name)\n",
    "            try:\n",
    "                image = cv2.imread(img_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                features = extract_features(image)\n",
    "                features['label'] = label\n",
    "                feature_list.append(features)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return pd.DataFrame(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features...\n",
      "Feature extraction completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Extracting features...\")\n",
    "features_df = process_dataset(dataset_dir)\n",
    "\n",
    "features_df.to_csv(\"tree_features.csv\", index=False)\n",
    "print(\"Feature extraction completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting classification...\n"
     ]
    }
   ],
   "source": [
    "# Classification\n",
    "print(\"Starting classification...\")\n",
    "# Separate features and labels\n",
    "X = features_df.drop(columns=[\"label\"])\n",
    "y = features_df[\"label\"]\n",
    "\n",
    "y = y.astype('category').cat.codes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"SVM\": SVC(kernel=\"rbf\", random_state=42),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating Random Forest...\n",
      "Accuracy: 0.6510\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.64      0.63      0.64       500\n",
      "   live_wood       0.78      0.75      0.77       473\n",
      "    pink_wax       0.65      0.68      0.66       471\n",
      " stem_canker       0.54      0.54      0.54       470\n",
      "\n",
      "    accuracy                           0.65      1914\n",
      "   macro avg       0.65      0.65      0.65      1914\n",
      "weighted avg       0.65      0.65      0.65      1914\n",
      "\n",
      "\n",
      "Training and evaluating SVM...\n",
      "Accuracy: 0.6870\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.69      0.63      0.66       500\n",
      "   live_wood       0.82      0.81      0.81       473\n",
      "    pink_wax       0.71      0.72      0.72       471\n",
      " stem_canker       0.54      0.59      0.56       470\n",
      "\n",
      "    accuracy                           0.69      1914\n",
      "   macro avg       0.69      0.69      0.69      1914\n",
      "weighted avg       0.69      0.69      0.69      1914\n",
      "\n",
      "\n",
      "Training and evaluating KNN...\n",
      "Accuracy: 0.5878\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     healthy       0.56      0.63      0.59       500\n",
      "   live_wood       0.71      0.69      0.70       473\n",
      "    pink_wax       0.58      0.62      0.60       471\n",
      " stem_canker       0.49      0.40      0.44       470\n",
      "\n",
      "    accuracy                           0.59      1914\n",
      "   macro avg       0.59      0.59      0.58      1914\n",
      "weighted avg       0.59      0.59      0.58      1914\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining and evaluating {model_name}...\")\n",
    "    \n",
    "    if model_name in [\"SVM\", \"KNN\"]:\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Metrics\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=features_df['label'].unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TenserFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
